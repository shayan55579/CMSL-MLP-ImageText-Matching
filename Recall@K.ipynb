{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def aggregated_vectors(file_path, aggregation_method='mean'):\n",
    "    \"\"\"\n",
    "    Aggregates vectors by image name using the specified aggregation method.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: str, the path to the CSV file containing the vectors and image names.\n",
    "    - aggregation_method: str, the method of aggregation ('mean', 'sum', 'max', 'min', etc.).\n",
    "\n",
    "    Returns:\n",
    "    - aggregated_vectors: DataFrame, the aggregated vectors by image name.\n",
    "    \"\"\"\n",
    "    # Load the file\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Exclude the 'Caption' column before grouping\n",
    "    data_without_caption = data.drop(columns=['Caption'])\n",
    "\n",
    "    # Group the data by 'ImageName' and aggregate using the specified method\n",
    "    if aggregation_method in ['mean', 'sum', 'max', 'min']:\n",
    "        aggregated_vectors = data_without_caption.groupby('ImageName').agg(aggregation_method)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported aggregation method. Choose 'mean', 'sum', 'max', or 'min'.\")\n",
    "\n",
    "    return aggregated_vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Text.csv'  # Update this to your file path\n",
    "aggregation_method = 'mean'  # Change this to 'sum', 'max', 'min', etc., as needed\n",
    "\n",
    "aggregated_vectors_text = aggregated_vectors(file_path, aggregation_method)\n",
    "print(aggregated_vectors_text.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_vectors_no_tensor(file_path, aggregation_method='mean'):\n",
    "    \"\"\"\n",
    "    Aggregates vectors by image name using the specified aggregation method, excluding tensor-like columns.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: str, the path to the CSV file containing the vectors and image names without headers.\n",
    "    - aggregation_method: str, the method of aggregation ('mean', 'sum', 'max', 'min', etc.).\n",
    "\n",
    "    Returns:\n",
    "    - aggregated_vectors: DataFrame, the aggregated vectors by image name.\n",
    "    \"\"\"\n",
    "    # Load the file without headers\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    \n",
    "    # Identify the image name column (last column) and exclude the tensor-like column (second last column)\n",
    "    columns_to_use = list(range(data.shape[1] - 2)) + [data.shape[1] - 1]\n",
    "    data_filtered = data[columns_to_use]\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    new_column_names = [f'Vector_{i}' for i in range(data_filtered.shape[1] - 1)] + ['ImageName']\n",
    "    data_filtered.columns = new_column_names\n",
    "\n",
    "    # Group the data by 'ImageName' and aggregate using the specified method\n",
    "    if aggregation_method in ['mean', 'sum', 'max', 'min']:\n",
    "        aggregated_vectors = data_filtered.groupby('ImageName').agg(aggregation_method)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported aggregation method. Choose 'mean', 'sum', 'max', or 'min'.\")\n",
    "\n",
    "    return aggregated_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Image.csv'  # Update this to your file path\n",
    "aggregation_method = 'mean'  # Change this to 'sum', 'max', 'min', etc., as needed\n",
    "\n",
    "aggregated_vectors_image = aggregate_vectors_no_tensor(file_path, aggregation_method)\n",
    "print(aggregated_vectors_image.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_vectors_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def transform_vectors(vectors, weight_matrix):\n",
    "    \"\"\"\n",
    "    Transforms vectors by multiplying with a weight matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - vectors: NumPy array of vectors to be transformed.\n",
    "    - weight_matrix: NumPy array representing the weight matrix.\n",
    "\n",
    "    Returns:\n",
    "    - transformed_vectors: The vectors after transformation.\n",
    "    \"\"\"\n",
    "    return np.dot(vectors, weight_matrix)\n",
    "\n",
    "def calculate_recall_at_k(image_vectors, text_vectors, weight_matrix, image_names, k=1):\n",
    "    \"\"\"\n",
    "    Calculates Recall@K for a set of image vectors and corresponding text vectors using a weight matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - image_vectors: NumPy array of aggregated image vectors.\n",
    "    - text_vectors: NumPy array of text vectors corresponding to the images.\n",
    "    - weight_matrix: NumPy array representing the weight matrix for transforming vectors.\n",
    "    - image_names: List of image names corresponding to both image and text vectors.\n",
    "    - k: The number of top-ranked items to consider for calculating recall.\n",
    "\n",
    "    Returns:\n",
    "    - recall_at_k: The Recall@K score.\n",
    "    \"\"\"\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # Transform text vectors using the weight matrix\n",
    "    transformed_text_vectors = transform_vectors(text_vectors, weight_matrix)\n",
    "\n",
    "    for index, image_vector in enumerate(image_vectors):\n",
    "        # Calculate similarities between the current image vector and all transformed text vectors\n",
    "        similarities = cosine_similarity([image_vector], transformed_text_vectors)[0]\n",
    "        \n",
    "        # Get the indices of the texts in descending order of similarity\n",
    "        ranked_indices = np.argsort(similarities)[::-1]\n",
    "        \n",
    "        # Check if the correct text is within the top K\n",
    "        correct_index = image_names.index(image_names[index])\n",
    "        if correct_index in ranked_indices[:k]:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    recall_at_k = correct_predictions / len(image_vectors)\n",
    "    return recall_at_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weight matrix from the binary file\n",
    "best_solution_matrix = np.load(r\"E:\\MScoco\\Weights\\best_solution_matrix.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_solution_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image names from the DataFrame index\n",
    "image_names = list(aggregated_vectors_image.index)\n",
    "image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names_text = list(aggregated_vectors_text.index)\n",
    "image_names_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(image_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to NumPy array (make sure to sort both DataFrames by index to ensure alignment)\n",
    "aggregated_vectors_image_np = aggregated_vectors_image.sort_index().to_numpy()\n",
    "aggregated_vectors_text_np = aggregated_vectors_text.sort_index().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "recall_at_k_score = calculate_recall_at_k(aggregated_vectors_image_np, aggregated_vectors_text_np, best_solution_matrix, image_names, k)\n",
    "print(f\"Recall@{k}: {recall_at_k_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image retival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Adjust the path as necessary to load your CSV file and .npy file\n",
    "image_df = pd.read_csv('Image.csv')\n",
    "best_solution_matrix = np.load(r\"E:\\MScoco\\Weights\\best_solution_matrix_new_700_Parse.npy\")\n",
    "\n",
    "# Assuming the first columns are feature vectors and the last column is 'ImageName'\n",
    "features = image_df.iloc[:, :-2].values\n",
    "image_names = image_df.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform feature vectors using the weights matrix\n",
    "transformed_features = np.dot(features, best_solution_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute cosine similarities for all pairs of images\n",
    "similarities = cosine_similarity(transformed_features)\n",
    "\n",
    "# For simplicity, setting the diagonal to -np.inf to ignore self-similarity\n",
    "np.fill_diagonal(similarities, -np.inf)\n",
    "\n",
    "# Rank images based on similarity for each query (image)\n",
    "ranks = np.argsort(similarities, axis=1)[:, ::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for relevance criteria - you need to define this part\n",
    "def is_relevant(query_image_name, candidate_image_name):\n",
    "    # Implement your relevance criteria here\n",
    "    return query_image_name == candidate_image_name\n",
    "\n",
    "# Calculate R@K\n",
    "K = 10  # Example for R@5\n",
    "correct_counts = np.zeros(len(image_names))\n",
    "\n",
    "for i, query_idx in enumerate(ranks):\n",
    "    query_image_name = image_names[i]\n",
    "    for rank in query_idx[:K]:\n",
    "        if is_relevant(query_image_name, image_names[rank]):\n",
    "            correct_counts[i] = 1\n",
    "            break\n",
    "\n",
    "recall_at_k = np.mean(correct_counts)\n",
    "print(f'Recall@{K}: {recall_at_k}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image-to-Text Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the file path as necessary for your setup\n",
    "best_solution_matrix = np.load(r'E:\\\\MScoco\\\\Weights\\\\best_solution_matrix_new_700_Parse.npy')\n",
    "# Load the image and text datasets\n",
    "image_df = pd.read_csv('Image.csv')\n",
    "text_df = pd.read_csv('Text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the first columns before the last two are the feature vectors\n",
    "image_features = image_df.iloc[:, :-2].values\n",
    "text_features = text_df.iloc[:, :-2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_solution_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Transform both image and text features by the weights matrix\n",
    "transformed_image_features = np.dot(image_features, best_solution_matrix)\n",
    "transformed_text_features = np.dot(text_features, best_solution_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarities between transformed image and text features\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(transformed_image_features, transformed_text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10  # Adjust as needed\n",
    "ranked_indices = np.argsort(-cosine_sim, axis=1)[:, :K]\n",
    "hits = 0\n",
    "\n",
    "for i in range(len(image_df)):\n",
    "    image_name = image_df.iloc[i, -1]\n",
    "    relevant_text_indices = text_df.index[text_df['ImageName'] == image_name].tolist()\n",
    "    top_k_indices = ranked_indices[i, :K]\n",
    "    \n",
    "    # Print image names and their top K retrieved texts\n",
    "    print(f\"Image Name: {image_name}\")\n",
    "    for rank, text_index in enumerate(top_k_indices, start=1):\n",
    "        print(f\"  Rank {rank}: {text_df.iloc[text_index]['Caption']}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Simple recall calculation\n",
    "    if any(idx in top_k_indices for idx in relevant_text_indices):\n",
    "        hits += 1\n",
    "\n",
    "recall = hits / len(image_df)\n",
    "print(f\"Recall@{K}: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume all previous steps are as before\n",
    "\n",
    "print(f\"Total number of images: {len(image_df)}\")\n",
    "print(f\"Total number of texts: {len(text_df)}\")\n",
    "print(f\"Shape of transformed image features: {transformed_image_features.shape}\")\n",
    "print(f\"Shape of transformed text features: {transformed_text_features.shape}\")\n",
    "\n",
    "# Calculate cosine similarity and find top K indices as before\n",
    "\n",
    "hits = 0\n",
    "\n",
    "for i in range(len(image_df)):\n",
    "    image_name = image_df.iloc[i, -1]\n",
    "    relevant_text_indices = text_df.index[text_df['ImageName'] == image_name].tolist()\n",
    "    top_k_indices = ranked_indices[i, :K]\n",
    "    \n",
    "    # Debugging print: Image name and its relevant texts' indices\n",
    "    print(f\"\\nImage Name: {image_name}, Relevant Text Indices: {relevant_text_indices}, Top K Indices: {top_k_indices}\")\n",
    "    \n",
    "    # Print top K retrieved texts for debugging\n",
    "    for rank, text_index in enumerate(top_k_indices, start=1):\n",
    "        caption = text_df.iloc[text_index]['Caption']\n",
    "        print(f\"  Rank {rank}: {caption} (Index: {text_index})\")\n",
    "\n",
    "    # Check for hits\n",
    "    if any(idx in top_k_indices for idx in relevant_text_indices):\n",
    "        hits += 1\n",
    "        print(\"Relevant text found in top K.\")\n",
    "    else:\n",
    "        print(\"Relevant text NOT found in top K.\")\n",
    "\n",
    "# Detailed recall calculation printout\n",
    "recall = hits / len(image_df)\n",
    "print(f\"\\nHits: {hits}\")\n",
    "print(f\"Total Images: {len(image_df)}\")\n",
    "print(f\"Recall@{K}: {recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall1 = hits / len(common_names)\n",
    "print(f\"Recall@{K}: {recall1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New based on the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the file path as necessary for your setup\n",
    "best_solution_matrix = np.load(r'E:\\\\MScoco\\\\Weights\\\\best_solution_matrix_new_700_Parse.npy')\n",
    "# Load the image and text datasets\n",
    "image_df = pd.read_csv('Updated_Image.csv')\n",
    "text_df = pd.read_csv('Updated_Text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the first columns before the last two are the feature vectors\n",
    "image_features = image_df.iloc[:, :-2].values\n",
    "text_features = text_df.iloc[:, :-3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Transform both image and text features by the weights matrix\n",
    "transformed_image_features = np.dot(image_features, best_solution_matrix)\n",
    "transformed_text_features = np.dot(text_features, best_solution_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(transformed_image_features, transformed_text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10  # Adjust as needed\n",
    "ranked_indices = np.argsort(-cosine_sim, axis=1)[:, :K]\n",
    "hits = 0\n",
    "total_relevant_items = 0\n",
    "\n",
    "for i in range(len(image_df)):\n",
    "    image_label = image_df.iloc[i, 10]  # Adjust index as per your dataset\n",
    "    relevant_text_indices = text_df.index[text_df.iloc[:, 10] == image_label].tolist()\n",
    "    top_k_indices = ranked_indices[i, :K]\n",
    "    \n",
    "    # Calculate the number of relevant items in top K\n",
    "    relevant_items_count = sum(idx in top_k_indices for idx in relevant_text_indices)\n",
    "    total_relevant_items += relevant_items_count\n",
    "    \n",
    "    # For each image, print the number of relevant items found in top K\n",
    "    print(f\"Image {i+1}: {relevant_items_count} relevant items found in top {K}\")\n",
    "    \n",
    "    # Simple recall calculation\n",
    "    if relevant_items_count > 0:\n",
    "        hits += 1\n",
    "\n",
    "recall = hits / len(image_df)\n",
    "print(f\"\\nTotal relevant items found: {total_relevant_items}\")\n",
    "print(f\"Recall@{K}: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate recall\n",
    "def calculate_recall_for_K(K):\n",
    "    ranked_indices = np.argsort(-cosine_sim, axis=1)[:, :K]\n",
    "    hits = 0\n",
    "\n",
    "    for i in range(len(image_df)):\n",
    "        image_label = image_df.iloc[i, 10]  # Adjust index as per your dataset\n",
    "        relevant_text_indices = text_df.index[text_df.iloc[:, 10] == image_label].tolist()\n",
    "        top_k_indices = ranked_indices[i, :K]\n",
    "        \n",
    "        # Check if there's at least one relevant item in top K\n",
    "        if any(idx in top_k_indices for idx in relevant_text_indices):\n",
    "            hits += 1\n",
    "\n",
    "    recall = hits / len(image_df)\n",
    "    return recall\n",
    "\n",
    "# List of K values to calculate recall for\n",
    "K_values = [1, 2, 5, 10]\n",
    "print('hits',hits)\n",
    "print(\"Total Images:\",len(image_df))\n",
    "# Calculate and print recall for each K\n",
    "for K in K_values:\n",
    "    recall = calculate_recall_for_K(K)\n",
    "    print(f\"Recall@{K}: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate recall\n",
    "def calculate_recall_for_K(K):\n",
    "    ranked_indices = np.argsort(-cosine_sim, axis=1)[:, :K]\n",
    "    hits = 0\n",
    "\n",
    "    for i in range(len(image_df)):\n",
    "        image_label = image_df.iloc[i, 10]  # Adjust index as per your dataset\n",
    "        relevant_text_indices = text_df.index[text_df.iloc[:, 10] == image_label].tolist()\n",
    "        top_k_indices = ranked_indices[i, :K]\n",
    "        \n",
    "        # Check if there's at least one relevant item in top K\n",
    "        if any(idx in top_k_indices for idx in relevant_text_indices):\n",
    "            hits += 1\n",
    "\n",
    "    recall = hits / len(image_df)\n",
    "    return recall\n",
    "\n",
    "# List of K values to calculate recall for\n",
    "K_values = [1, 2, 5, 10]\n",
    "\n",
    "# Calculate and print recall for each K\n",
    "for K in K_values:\n",
    "    recall = calculate_recall_for_K(K)\n",
    "    # Format recall as a percentage with one decimal place\n",
    "    print(f\"Recall@{K}: {recall:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With the other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the file path as necessary for your setup\n",
    "best_solution_matrix = np.load(r'E:\\\\MScoco\\\\Weights\\\\best_solution_matrix_new_700_Parse.npy')\n",
    "# Load the image and text datasets\n",
    "image_df = pd.read_csv(r'E:\\MScoco\\R@K\\full\\NewTest\\new_100_img_pca_10.csv')\n",
    "text_df = pd.read_csv(r'E:\\MScoco\\R@K\\full\\NewTest\\new_100_Text_pca_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the first columns before the last two are the feature vectors\n",
    "image_features = image_df.iloc[:, :-2].values\n",
    "text_features = text_df.iloc[:, :-3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Transform both image and text features by the weights matrix\n",
    "transformed_image_features = np.dot(image_features, best_solution_matrix)\n",
    "transformed_text_features = np.dot(text_features, best_solution_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(transformed_image_features, transformed_text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10  # Adjust as needed\n",
    "ranked_indices = np.argsort(-cosine_sim, axis=1)[:, :K]\n",
    "hits = 0\n",
    "total_relevant_items = 0\n",
    "\n",
    "for i in range(len(image_df)):\n",
    "    image_label = image_df.iloc[i, 10]  # Adjust index as per your dataset\n",
    "    relevant_text_indices = text_df.index[text_df.iloc[:, 10] == image_label].tolist()\n",
    "    top_k_indices = ranked_indices[i, :K]\n",
    "    \n",
    "    # Calculate the number of relevant items in top K\n",
    "    relevant_items_count = sum(idx in top_k_indices for idx in relevant_text_indices)\n",
    "    total_relevant_items += relevant_items_count\n",
    "    \n",
    "    # For each image, print the number of relevant items found in top K\n",
    "    print(f\"Image {i+1}: {relevant_items_count} relevant items found in top {K}\")\n",
    "    \n",
    "    # Simple recall calculation\n",
    "    if relevant_items_count > 0:\n",
    "        hits += 1\n",
    "\n",
    "recall = hits / len(image_df)\n",
    "print(f\"\\nTotal relevant items found: {total_relevant_items}\")\n",
    "print(f\"Recall@{K}: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate recall\n",
    "def calculate_recall_for_K(K):\n",
    "    ranked_indices = np.argsort(-cosine_sim, axis=1)[:, :K]\n",
    "    hits = 0\n",
    "\n",
    "    for i in range(len(image_df)):\n",
    "        image_label = image_df.iloc[i, 10]  # Adjust index as per your dataset\n",
    "        relevant_text_indices = text_df.index[text_df.iloc[:, 10] == image_label].tolist()\n",
    "        top_k_indices = ranked_indices[i, :K]\n",
    "        \n",
    "        # Check if there's at least one relevant item in top K\n",
    "        if any(idx in top_k_indices for idx in relevant_text_indices):\n",
    "            hits += 1\n",
    "\n",
    "    recall = hits / len(image_df)\n",
    "    return recall\n",
    "\n",
    "# List of K values to calculate recall for\n",
    "K_values = [1, 2, 5, 10]\n",
    "print('hits',hits)\n",
    "print(\"Total Images:\",len(image_df))\n",
    "# Calculate and print recall for each K\n",
    "for K in K_values:\n",
    "    recall = calculate_recall_for_K(K)\n",
    "    print(f\"Recall@{K}: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate recall\n",
    "def calculate_recall_for_K(K):\n",
    "    ranked_indices = np.argsort(-cosine_sim, axis=1)[:, :K]\n",
    "    hits = 0\n",
    "\n",
    "    for i in range(len(image_df)):\n",
    "        image_label = image_df.iloc[i, 10]  # Adjust index as per your dataset\n",
    "        relevant_text_indices = text_df.index[text_df.iloc[:, 10] == image_label].tolist()\n",
    "        top_k_indices = ranked_indices[i, :K]\n",
    "        \n",
    "        # Check if there's at least one relevant item in top K\n",
    "        if any(idx in top_k_indices for idx in relevant_text_indices):\n",
    "            hits += 1\n",
    "\n",
    "    recall = hits / len(image_df)\n",
    "    return recall\n",
    "\n",
    "# List of K values to calculate recall for\n",
    "K_values = [1, 2, 5, 10]\n",
    "\n",
    "# Calculate and print recall for each K\n",
    "for K in K_values:\n",
    "    recall = calculate_recall_for_K(K)\n",
    "    # Format recall as a percentage with one decimal place\n",
    "    print(f\"Recall@{K}: {recall:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Adjust the file path as necessary for your setup\n",
    "best_solution_matrix = np.load(r'E:\\\\MScoco\\\\Weights\\\\best_solution_matrix_new_700_Parse.npy')\n",
    "# Load the image and text datasets\n",
    "image_df = pd.read_csv(r'E:\\MScoco\\R@K\\full\\NewTest\\new_100_img_pca_10.csv')\n",
    "text_df = pd.read_csv(r'E:\\MScoco\\R@K\\full\\NewTest\\new_100_Text_pca_10.csv')\n",
    "# Assuming the first columns before the last two are the feature vectors\n",
    "image_features = image_df.iloc[:, :-2].values\n",
    "text_features = text_df.iloc[:, :-3].values\n",
    "\n",
    " #Transform both image and text features by the weights matrix\n",
    "transformed_image_features = np.dot(image_features, best_solution_matrix)\n",
    "transformed_text_features = np.dot(text_features, best_solution_matrix)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming image_names and caption_image_names are extracted as follows\n",
    "image_names = image_df.iloc[:, -1]  # Image names for the image dataset\n",
    "captions = text_df.iloc[:, -1]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert transformed features into DataFrames for easier manipulation\n",
    "df_transformed_image_features = pd.DataFrame(transformed_image_features)\n",
    "df_transformed_image_features['ImageName'] = image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed_image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line already does what you're asking for: It aggregates the features by 'ImageName',\n",
    "# calculates the mean of these features for each unique 'ImageName', and retains the 'ImageName' in the result.\n",
    "aggregated_image_features = df_transformed_image_features.groupby('ImageName').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed_text_features = pd.DataFrame(transformed_text_features)\n",
    "df_transformed_text_features['captions'] = captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed_text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_image_text = df_transformed_text_features.groupby('captions').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_image_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_image_names = text_df.iloc[:, -2]  # Image names associated with captions in the second-last column of text_df\n",
    "\n",
    "# Step 1: Create a mapping from captions to their associated image names\n",
    "# Since the structure is different, we use the directly provided caption_image_names\n",
    "caption_to_image_mapping = dict(zip(captions, caption_image_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_to_image_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the 'map' function to replace captions with image names\n",
    "# This will create a new column 'ImageName' with the mapped values\n",
    "aggregated_image_text['ImageName'] = aggregated_image_text['captions'].map(caption_to_image_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, if you want to remove the original 'captions' column and retain the rest unchanged\n",
    "new_df_text = aggregated_image_text.drop('captions', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both dataframes have the same number of rows (matching the number of rows in aggregated_image_features)\n",
    "new_df_text_filtered = new_df_text.iloc[:62, :]  # Adjust the number (62) as needed\n",
    "\n",
    "# Extracting the vectors from both filtered dataframes (assuming columns 1 to 10 are the vectors)\n",
    "vectors_text = new_df_text_filtered.iloc[:, :10]\n",
    "vectors_image = aggregated_image_features.iloc[:, 1:]\n",
    "\n",
    "# Calculate cosine similarity matrix\n",
    "cosine_similarity_matrix = cosine_similarity(vectors_text, vectors_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting image names from the first column of filtered aggregated_image_features\n",
    "image_names_image = aggregated_image_features.iloc[:62, 0].values  # Adjust the number (62) as needed\n",
    "\n",
    "# Extracting image names from the last column of new_df_text_filtered\n",
    "image_names_text = new_df_text_filtered.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of new_df_text:\", new_df_text.shape)\n",
    "print(\"Shape of aggregated_image_features:\", aggregated_image_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(image_names_text, image_names_image, k):\n",
    "    num_correct = 0\n",
    "    for i, image_name_text in enumerate(image_names_text):\n",
    "        top_k_indices = np.argsort(-1 * cosine_similarity_matrix[i])[:k]\n",
    "        if image_names_image[i] in [image_names_text[index] for index in top_k_indices]:\n",
    "            num_correct += 1\n",
    "    recall = num_correct / len(image_names_text)\n",
    "    return recall\n",
    "\n",
    "# Calculate Recall@1, Recall@5, Recall@10\n",
    "recall_1 = recall_at_k(image_names_text, image_names_image, 1)\n",
    "recall_5 = recall_at_k(image_names_text, image_names_image, 5)\n",
    "recall_10 = recall_at_k(image_names_text, image_names_image, 10)\n",
    "\n",
    "print(f\"Recall@1: {recall_1*100:.2f}%\")\n",
    "print(f\"Recall@5: {recall_5*100:.2f}%\")\n",
    "print(f\"Recall@10: {recall_10*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(image_names_text, image_names_image, k, cosine_similarity_matrix):\n",
    "    num_correct = 0\n",
    "    for i, image_name_text in enumerate(image_names_text):\n",
    "        top_k_indices = np.argsort(-1 * cosine_similarity_matrix[i])[:k]\n",
    "        print(f\"Top {k} indices for image name {image_name_text}: {top_k_indices}\")\n",
    "        if image_names_image[i] in [image_names_text[index] for index in top_k_indices]:\n",
    "            num_correct += 1\n",
    "    recall = num_correct / len(image_names_text)\n",
    "    return recall\n",
    "\n",
    "# Calculate Recall@1, Recall@5, Recall@10\n",
    "recall_1 = recall_at_k(image_names_text, image_names_image, 1, cosine_similarity_matrix)\n",
    "recall_5 = recall_at_k(image_names_text, image_names_image, 5, cosine_similarity_matrix)\n",
    "recall_10 = recall_at_k(image_names_text, image_names_image, 10, cosine_similarity_matrix)\n",
    "\n",
    "print(f\"Recall@1: {recall_1*100:.2f}%\")\n",
    "print(f\"Recall@5: {recall_5*100:.2f}%\")\n",
    "print(f\"Recall@10: {recall_10*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20x20 R@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_recall_and_print(image_path, text_path, best_solution_matrix_path,index_label):\n",
    "    # Load the best solution matrix\n",
    "    best_solution_matrix = np.load(best_solution_matrix_path)\n",
    "    \n",
    "    # Load the image and text datasets\n",
    "    image_df = pd.read_csv(image_path)\n",
    "    text_df = pd.read_csv(text_path)\n",
    "    \n",
    "    # Assuming the first columns before the last two are the feature vectors\n",
    "    image_features = image_df.iloc[:, :-2].values\n",
    "    text_features = text_df.iloc[:, :-3].values\n",
    "    \n",
    "    # Transform both image and text features by the weights matrix\n",
    "    transformed_image_features = np.dot(image_features, best_solution_matrix)\n",
    "    transformed_text_features = np.dot(text_features, best_solution_matrix)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    cosine_sim = cosine_similarity(transformed_image_features, transformed_text_features)\n",
    "    \n",
    "    # Print the size of the datasets\n",
    "    print(\"Size of image dataset:\", image_features.shape)\n",
    "    print(\"Size of text dataset:\", text_features.shape)\n",
    "    print('Size of best solution matrix:', best_solution_matrix.shape)\n",
    "    \n",
    "    # Function to calculate recall\n",
    "    def calculate_recall_for_K(K):\n",
    "        ranked_indices = np.argsort(-cosine_sim, axis=1)[:, :K]\n",
    "        hits = 0\n",
    "\n",
    "        for i in range(len(image_df)):\n",
    "            image_label = image_df.iloc[i, index_label]  # Adjust index as per your dataset\n",
    "            relevant_text_indices = text_df.index[text_df.iloc[:, index_label] == image_label].tolist()\n",
    "            top_k_indices = ranked_indices[i, :K]\n",
    "            \n",
    "            # Check if there's at least one relevant item in top K\n",
    "            if any(idx in top_k_indices for idx in relevant_text_indices):\n",
    "                hits += 1\n",
    "\n",
    "        recall = hits / len(image_df)\n",
    "        return recall\n",
    "\n",
    "    # List of K values to calculate recall for\n",
    "    K_values = [1,5,10]\n",
    "\n",
    "    # Calculate and print recall for each K\n",
    "    for K in K_values:\n",
    "        recall = calculate_recall_for_K(K)\n",
    "        # Format recall as a percentage with one decimal place\n",
    "        print(f\"Recall@{K}: {recall:.1%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "image_path=r\"E:\\MScoco\\R@K\\full\\NewTest\\new_100_img_pca_20.csv\"\n",
    "text_path=r\"E:\\MScoco\\R@K\\full\\NewTest\\new_100_Text_pca_20.csv\"\n",
    "best_solution_matrix_path=r\"E:\\MScoco\\Weights\\best_solution_matrix_NEW_S_file7_20tanewVersion800.npy\"\n",
    "calculate_recall_and_print(image_path,text_path,best_solution_matrix_path,20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
