{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def print_captions_for_image(image_names_file):\n",
    "    file_path = r'captions_train2017.json'\n",
    "    \n",
    "    # Load the JSON data from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Read the image names from the provided text file\n",
    "    with open(image_names_file, 'r') as file:\n",
    "        # Read lines and remove any leading or trailing whitespace\n",
    "        image_names = [line.strip() for line in file.readlines()]\n",
    "\n",
    "    num_images = len(image_names)  # Count the number of images\n",
    "\n",
    "    # Construct the output file name with the number of images\n",
    "    output_file_name = f\"Part2_{num_images}.txt\"\n",
    "    captions_output_file = os.path.join(r\"ImageNames\", output_file_name)\n",
    "\n",
    "    # Open the output file to write captions\n",
    "    with open(captions_output_file, 'w') as out_file:\n",
    "        for image_name in image_names:\n",
    "            # Clean up the image name\n",
    "            cleaned_image_name = image_name.strip().replace('\\'', '').replace('\"', '')\n",
    "\n",
    "            # Find the image ID corresponding to the given image name\n",
    "            image_id = None\n",
    "            for image in data['images']:\n",
    "                if image['file_name'] == cleaned_image_name:\n",
    "                    image_id = image['id']\n",
    "                    break\n",
    "            \n",
    "            # If the image ID was found, write the image name and its captions, otherwise print a message\n",
    "            if image_id is not None:\n",
    "                out_file.write(f'{cleaned_image_name}\\n')  # Write the image name\n",
    "                captions = [annotation['caption'] for annotation in data['annotations'] if annotation['image_id'] == image_id]\n",
    "                for caption in captions:\n",
    "                    out_file.write(f'{caption}\\n')\n",
    "                out_file.write('\\n')  # Add an extra newline for separation between different images\n",
    "            else:\n",
    "                print(f'No captions found for image: {cleaned_image_name}')\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "image_names_file = r\"\\name_2k_ta_7k_3493.txt\"\n",
    "print_captions_for_image(image_names_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def print_captions_for_image(image_name):# get the image name\n",
    "\n",
    "    file_path = r'captions_train2017.json'\n",
    "    # Load the JSON data from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Find the image ID corresponding to the given image name\n",
    "    image_id = None\n",
    "    for image in data['images']:\n",
    "        if image['file_name'] == image_name:\n",
    "            image_id = image['id']\n",
    "            break\n",
    "    \n",
    "    # If the image ID was found, print all captions associated with this image\n",
    "    if image_id is not None:\n",
    "        print(f'Captions for {image_name}:')\n",
    "        captions = [annotation['caption'] for annotation in data['annotations'] if annotation['image_id'] == image_id]\n",
    "        for i, caption in enumerate(captions, start=1):\n",
    "            print(f'Caption {i}: {caption}')\n",
    "    else:\n",
    "        print(f'No captions found for image: {image_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_captions_for_image('000000000764.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "def process_mat_file(file_path):\n",
    "    # Load .mat file\n",
    "    mat = scipy.io.loadmat(file_path)\n",
    "    \n",
    "    # Accessing the data stored under the 'result' key\n",
    "    result_data = mat['result']\n",
    "    \n",
    "    # Accessing the 'best_solution' field within the 'result' dictionary\n",
    "    best_solution_array = result_data['best_solution']\n",
    "    \n",
    "    # Extracting the inner array\n",
    "    best_solution_inner_array = best_solution_array[0]\n",
    "    \n",
    "    # Extracting the actual data from the inner array\n",
    "    best_solution_data = best_solution_inner_array[0]\n",
    "    \n",
    "    # Reshape the data to a 10x10 matrix\n",
    "    best_solution_matrix = best_solution_data.reshape(10, 10)\n",
    "    \n",
    "    # Check the size of the resized matrix\n",
    "    print(\"Size of the resized matrix:\", best_solution_matrix.shape)\n",
    "    \n",
    "    # Save the matrix as a binary file\n",
    "    np.save('WeightNewHyperPar_1000_10x10.npy', best_solution_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "process_mat_file(r\"WeightNewHyperPar_1000_10x10.mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_recall_and_print(image_path, text_path, best_solution_matrix_path,index_label):\n",
    "    # Load the best solution matrix\n",
    "    best_solution_matrix = np.load(best_solution_matrix_path)\n",
    "    \n",
    "    # Load the image and text datasets\n",
    "    image_df = pd.read_csv(image_path)\n",
    "    text_df = pd.read_csv(text_path)\n",
    "    \n",
    "    # Assuming the first columns before the last two are the feature vectors\n",
    "    image_features = image_df.iloc[:, :-2].values\n",
    "    text_features = text_df.iloc[:, :-3].values\n",
    "    \n",
    "    # Transform both image and text features by the weights matrix\n",
    "    transformed_image_features = np.dot(image_features, best_solution_matrix)\n",
    "    transformed_text_features = np.dot(text_features, best_solution_matrix)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    cosine_sim = cosine_similarity(transformed_image_features, transformed_text_features)\n",
    "    \n",
    "    # Print the size of the datasets\n",
    "    print(\"Size of image dataset:\", image_features.shape)\n",
    "    print(\"Size of text dataset:\", text_features.shape)\n",
    "    print('Size of best solution matrix:', best_solution_matrix.shape)\n",
    "    \n",
    "    # Function to calculate recall\n",
    "    def calculate_recall_for_K(K):\n",
    "        ranked_indices = np.argsort(-cosine_sim, axis=1)[:, :K]\n",
    "        hits = 0\n",
    "\n",
    "        for i in range(len(image_df)):\n",
    "            image_label = image_df.iloc[i, index_label]  # Adjust index as per your dataset\n",
    "            relevant_text_indices = text_df.index[text_df.iloc[:, index_label] == image_label].tolist()\n",
    "            top_k_indices = ranked_indices[i, :K]\n",
    "            \n",
    "            # Check if there's at least one relevant item in top K\n",
    "            if any(idx in top_k_indices for idx in relevant_text_indices):\n",
    "                hits += 1\n",
    "\n",
    "        recall = hits / len(image_df)\n",
    "        return recall\n",
    "\n",
    "    # List of K values to calculate recall for\n",
    "    K_values = [1,5,10]\n",
    "\n",
    "    # Calculate and print recall for each K\n",
    "    for K in K_values:\n",
    "        recall = calculate_recall_for_K(K)\n",
    "        # Format recall as a percentage with one decimal place\n",
    "        print(f\"Recall@{K}: {recall:.1%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "image_path=r\"new_100_img_pca_10.csv\"\n",
    "text_path=r\"new_100_Text_pca_10.csv\"\n",
    "best_solution_matrix_path=r\"best_solution.npy\"\n",
    "calculate_recall_and_print(image_path,text_path,best_solution_matrix_path,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_the_w(image_path, text_path, best_solution_matrix_path):\n",
    "    # Load the best solution matrix\n",
    "    best_solution_matrix = np.load(best_solution_matrix_path)\n",
    "    \n",
    "    # Load the image and text datasets\n",
    "    image_df = pd.read_csv(image_path)\n",
    "    text_df = pd.read_csv(text_path)\n",
    "    \n",
    "    # Assuming the first columns before the last two are the feature vectors\n",
    "    image_features = image_df.iloc[:, :-2].values\n",
    "    text_features = text_df.iloc[:, :-3].values\n",
    "    \n",
    "    # Transform both image and text features by the weights matrix\n",
    "    transformed_image_features = np.dot(image_features, best_solution_matrix)\n",
    "    transformed_text_features = np.dot(text_features, best_solution_matrix)\n",
    "    \n",
    "    # Plot original image and text features in 2D\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(image_features[:, 0], image_features[:, 1], c='blue', label='Image Features')\n",
    "    plt.scatter(text_features[:, 0], text_features[:, 1], c='red', label='Text Features')\n",
    "    plt.title('Source Space')\n",
    "    #plt.xlabel('Feature 1')\n",
    "    #plt.ylabel('Feature 2')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot transformed image and text features in 2D\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(transformed_image_features[:, 0], transformed_image_features[:, 1], c='blue', label='Transformed Image Features')\n",
    "    plt.scatter(transformed_text_features[:, 0], transformed_text_features[:, 1], c='red', label='Transformed Text Features')\n",
    "    plt.title('Target Space')\n",
    "    #plt.xlabel('Feature 1')\n",
    "    #plt.ylabel('Feature 2')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=r\"new_100_img_pca_10.csv\"\n",
    "text_path=r\"new_100_Text_pca_10.csv\"\n",
    "best_solution_matrix_path=r\"best_solution.npy\"\n",
    "plot_the_w(image_path,text_path,best_solution_matrix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_the_w2(image_path, text_path, best_solution_matrix_path, index_label):\n",
    "    # Load the best solution matrix\n",
    "    best_solution_matrix = np.load(best_solution_matrix_path)\n",
    "    \n",
    "    # Load the image and text datasets\n",
    "    image_df = pd.read_csv(image_path)\n",
    "    text_df = pd.read_csv(text_path)\n",
    "    \n",
    "    # Assuming the first columns before the last two are the feature vectors\n",
    "    image_features = image_df.iloc[:, :-2].values\n",
    "    text_features = text_df.iloc[:, :-3].values\n",
    "    \n",
    "    # Transform both image and text features by the weights matrix\n",
    "    transformed_image_features = np.dot(image_features, best_solution_matrix)\n",
    "    transformed_text_features = np.dot(text_features, best_solution_matrix)\n",
    "    \n",
    "    # Extract labels\n",
    "    image_labels = image_df.iloc[:, index_label].values\n",
    "    text_labels = text_df.iloc[:, index_label].values\n",
    "    \n",
    "    # Generate a color map\n",
    "    unique_labels = np.unique(np.concatenate((image_labels, text_labels)))\n",
    "    cmap = plt.get_cmap('tab10')\n",
    "    label_to_color = {label: cmap(i) for i, label in enumerate(unique_labels)}\n",
    "    \n",
    "    # Define marker shapes\n",
    "    markers = ['o', 's', 'D', '^', 'v', '<', '>', 'p', '*', 'h']\n",
    "    label_to_marker = {label: markers[i % len(markers)] for i, label in enumerate(unique_labels)}\n",
    "    \n",
    "    # Plot original image and text features in 2D\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    for label in unique_labels:\n",
    "        image_mask = image_labels == label\n",
    "        text_mask = text_labels == label\n",
    "        plt.scatter(image_features[image_mask, 0], image_features[image_mask, 1], \n",
    "                    c=[label_to_color[label]], marker=label_to_marker[label], edgecolor='k', label=f'Image {label}')\n",
    "        plt.scatter(text_features[text_mask, 0], text_features[text_mask, 1], \n",
    "                    c=[label_to_color[label]], marker=label_to_marker[label], edgecolor='k', label=f'Text {label}', alpha=0.7)\n",
    "    plt.title('Original Image and Text Features')\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    # Plot transformed image and text features in 2D\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for label in unique_labels:\n",
    "        image_mask = image_labels == label\n",
    "        text_mask = text_labels == label\n",
    "        plt.scatter(transformed_image_features[image_mask, 0], transformed_image_features[image_mask, 1], \n",
    "                    c=[label_to_color[label]], marker=label_to_marker[label], edgecolor='k', label=f'Transformed Image {label}')\n",
    "        plt.scatter(transformed_text_features[text_mask, 0], transformed_text_features[text_mask, 1], \n",
    "                    c=[label_to_color[label]], marker=label_to_marker[label], edgecolor='k', label=f'Transformed Text {label}', alpha=0.7)\n",
    "    plt.title('Transformed Image and Text Features')\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=r\"best_solution.npy\"\n",
    "text_path=r\"best_solution.npy\"\n",
    "best_solution_matrix_path=r\"best_solution.npy\"\n",
    "plot_the_w2(image_path,text_path,best_solution_matrix_path,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
