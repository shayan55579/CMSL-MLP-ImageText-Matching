{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnl4-5_KILsY"
   },
   "source": [
    "## Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9zWTgQ2HxaS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, BatchNormalization, Dropout, Flatten, Dense,Conv2D\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "# Custom cosine similarity metric\n",
    "def cosine_similarity_metric(y_true, y_pred):\n",
    "    y_true = K.l2_normalize(y_true, axis=-1)\n",
    "    y_pred = K.l2_normalize(y_pred, axis=-1)\n",
    "    return K.mean(K.sum(y_true * y_pred, axis=-1))\n",
    "\n",
    "# Load the data\n",
    "image_df = pd.read_csv('/content/Image_Transformed - Rasti.csv')\n",
    "text_df = pd.read_csv('/content/Text_Transformed - Rasti.csv')\n",
    "\n",
    "# Convert any non-numeric values to NaN\n",
    "# image_df.iloc[:, :-1] = image_df.iloc[:, :-1].apply(pd.to_numeric, errors='coerce')\n",
    "# text_df.iloc[:, :-1] = text_df.iloc[:, :-1].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "# Drop any rows with NaN values (if any)\n",
    "image_df.dropna(inplace=True)\n",
    "text_df.dropna(inplace=True)\n",
    "\n",
    "# Initialize the encoder\n",
    "encoder = LabelEncoder()\n",
    "# Fit the encoder on all image names (from both image and text data)\n",
    "all_image_names = np.concatenate((image_df.iloc[:, -1].values, text_df.iloc[:, -1].values))\n",
    "encoder.fit(all_image_names)\n",
    "\n",
    "# Transform the image names to encoded labels\n",
    "image_df['image_name_encoded'] = encoder.transform(image_df.iloc[:, -1].values)\n",
    "text_df['image_name_encoded'] = encoder.transform(text_df.iloc[:, -1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DONRWRdH4pN"
   },
   "outputs": [],
   "source": [
    "# Extract features from both datasets\n",
    "image_features = image_df.iloc[:, :-2].values\n",
    "text_features = text_df.iloc[:, :-2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPaIz0FuY7M4"
   },
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "combined_features = np.vstack((image_features, text_features))\n",
    "combined_features = scaler.fit_transform(combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDdagwWMH7YN"
   },
   "outputs": [],
   "source": [
    "# Combine image and text features into one large feature set\n",
    "combined_features = np.vstack((image_features, text_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDgN73CnXoja"
   },
   "source": [
    "### For the padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "is58Xmqv0Frz",
    "outputId": "14837012-bbbf-4187-f8bc-6710518e5057"
   },
   "outputs": [],
   "source": [
    "# Determine the maximum size for the second dimension\n",
    "max_dim = max(image_features.shape[1], text_features.shape[1])\n",
    "\n",
    "# Pad image_features and text_features to the same size in the second dimension\n",
    "padded_image_features = np.pad(image_features, ((0, 0), (0, max_dim - image_features.shape[1])), 'constant')\n",
    "padded_text_features = np.pad(text_features, ((0, 0), (0, max_dim - text_features.shape[1])), 'constant')\n",
    "\n",
    "# Combine the features\n",
    "combined_features = np.vstack((padded_image_features, padded_text_features))\n",
    "\n",
    "# Verify the shape of the combined features\n",
    "print(combined_features.shape)  # Should be (2084, max_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5B4G_9jbVoW"
   },
   "source": [
    "## continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fA_97AeH80t"
   },
   "outputs": [],
   "source": [
    "# Combine labels\n",
    "combined_labels = np.concatenate((image_df['image_name_encoded'].values, text_df['image_name_encoded'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJ9rdJtkIguC"
   },
   "outputs": [],
   "source": [
    "# Split the combined data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, combined_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxvT6sKAZIpv"
   },
   "outputs": [],
   "source": [
    "# Reshape for Conv1D\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1c3BzcIH-4k"
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv1D(32, 3, activation='relu', input_shape=(combined_features.shape[1], 1), kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Conv1D(64, 3, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Conv1D(128, 3, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(encoder.classes_), activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_kCTdhQIBW0"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[cosine_similarity_metric])\n",
    "\n",
    "# Add early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iq9yEWzPICkc",
    "outputId": "651ba4c5-9246-4a10-ec09-64e3641c7ab9"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G-nuveQOQGhQ",
    "outputId": "feebe63e-7f98-4838-e3ce-9c104d444ce5"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, cosine_sim = model.evaluate(X_test, y_test)\n",
    "print(f\"Loss: {loss}, Cosine Similarity: {cosine_sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "id": "QuA1Nsi-KaX3",
    "outputId": "72fa154b-7045-414c-ddac-fd4e08c53058"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "# Plot training & validation cosine similarity values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['cosine_similarity_metric'])\n",
    "plt.plot(history.history['val_cosine_similarity_metric'])\n",
    "plt.title('Model Cosine Similarity')\n",
    "plt.ylabel('Cosine Similarity')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hs2iZmxIIIEV"
   },
   "outputs": [],
   "source": [
    "def calculate_recall_at_k_with_names(model, X_test, y_test, encoder, k=1):\n",
    "    # Get predictions as probabilities\n",
    "    probabilities = model.predict(X_test)\n",
    "\n",
    "    # For each prediction, get the top K category indices\n",
    "    top_k_indices = np.argsort(-probabilities, axis=1)[:, :k]\n",
    "\n",
    "    # Decode these indices to actual names using the encoder\n",
    "    top_k_labels = np.vectorize(lambda x: encoder.classes_[x])(top_k_indices)\n",
    "\n",
    "    # Decode the true labels to names\n",
    "    true_labels_names = encoder.inverse_transform(y_test)\n",
    "\n",
    "    # Check if the true category name is within these top K predictions\n",
    "    matches = [true_labels_names[i] in top_k_labels[i] for i in range(len(y_test))]\n",
    "\n",
    "    # Calculate recall at K\n",
    "    recall_at_k = np.mean(matches)\n",
    "    return recall_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2P4_ItE4IJd_",
    "outputId": "4a92183e-3ca7-4a7d-9b4f-3252e7226761"
   },
   "outputs": [],
   "source": [
    "# Calculate Recall@K for K = 1, 5, 10\n",
    "k_values = [1, 5, 10]\n",
    "recalls = {f\"Recall@{k}\": calculate_recall_at_k_with_names(model, X_test, y_test, encoder, k) for k in k_values}\n",
    "\n",
    "# Print recalls formatted as percentages\n",
    "for k, recall in recalls.items():\n",
    "    print(f\"{k}: {recall:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NS6XkWHgJL0I"
   },
   "source": [
    "## Triple loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-8hgVJmJOEb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense,BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zjGLU8xJQ27"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "image_df = pd.read_csv('/content/Image_Transformed - Rasti.csv')\n",
    "text_df = pd.read_csv('/content/Text_Transformed - Rasti.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XHePZ--JSPK"
   },
   "outputs": [],
   "source": [
    "# Drop any rows with NaN values (if any)\n",
    "image_df.dropna(inplace=True)\n",
    "text_df.dropna(inplace=True)\n",
    "\n",
    "# Extract features and image names\n",
    "image_feature_values = image_df.iloc[:, :-1].values\n",
    "image_image_name_values = image_df.iloc[:, -1].values\n",
    "\n",
    "text_feature_values = text_df.iloc[:, :-1].values\n",
    "text_image_name_values = text_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cuTysMvJTqS"
   },
   "outputs": [],
   "source": [
    "# Create dataframes with labels as a column\n",
    "image_df = pd.DataFrame(image_feature_values)\n",
    "image_df['image_name'] = image_image_name_values\n",
    "\n",
    "text_df = pd.DataFrame(text_feature_values)\n",
    "text_df['image_name'] = text_image_name_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLsbYMlHJWjj"
   },
   "outputs": [],
   "source": [
    "# Find common image names\n",
    "common_image_names = np.intersect1d(image_image_name_values, text_image_name_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1nypimmJX86"
   },
   "outputs": [],
   "source": [
    "# Filter dataframes to include only common image names\n",
    "image_df = image_df[image_df['image_name'].isin(common_image_names)]\n",
    "text_df = text_df[text_df['image_name'].isin(common_image_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLahNOfIJZV_"
   },
   "outputs": [],
   "source": [
    "# Ensure the dataframes are sorted by image names\n",
    "image_df = image_df.sort_values(by='image_name')\n",
    "text_df = text_df.sort_values(by='image_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzsWxHAhJand"
   },
   "outputs": [],
   "source": [
    "# Merge dataframes on image names to ensure alignment\n",
    "aligned_df = pd.merge(image_df, text_df, on='image_name', suffixes=('_image', '_text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vF7OMczVJb-z"
   },
   "outputs": [],
   "source": [
    "# Extract aligned features and labels\n",
    "aligned_image_features = aligned_df.filter(regex='_image$').values\n",
    "aligned_text_features = aligned_df.filter(regex='_text$').values\n",
    "aligned_image_names = aligned_df['image_name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmaHIqftJdzu"
   },
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "aligned_image_features = scaler.fit_transform(aligned_image_features)\n",
    "aligned_text_features = scaler.fit_transform(aligned_text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "omFvl8jOJfV-",
    "outputId": "f73ec4b0-372f-4b4e-fa7b-fdf0f1fe989e"
   },
   "outputs": [],
   "source": [
    "# Debug statements to check lengths\n",
    "print(f\"Aligned image features length: {len(aligned_image_features)}\")\n",
    "print(f\"Aligned text features length: {len(aligned_text_features)}\")\n",
    "print(f\"Aligned image names length: {len(aligned_image_names)}\")\n",
    "# Ensure lengths match\n",
    "assert len(aligned_image_features) == len(aligned_text_features) == len(aligned_image_names), \"Lengths of aligned features and names do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQei8_FRJisD"
   },
   "outputs": [],
   "source": [
    "# Initialize and fit the label encoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(aligned_image_names)\n",
    "\n",
    "# Transform the image names to encoded labels\n",
    "labels_encoded = encoder.transform(aligned_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8u9WaRG1JkPd"
   },
   "outputs": [],
   "source": [
    "# Combine aligned features and labels into a single dataframe for splitting\n",
    "combined_df = pd.DataFrame(aligned_image_features)\n",
    "combined_df['text_features'] = list(aligned_text_features)\n",
    "combined_df['label'] = labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efMZ4Xh5Jlt9"
   },
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "train_df, test_df = train_test_split(combined_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rs-323egJnYt"
   },
   "outputs": [],
   "source": [
    "# Extract features and labels for training and testing sets\n",
    "image_train = np.array(train_df.iloc[:, :-2].values.tolist())\n",
    "text_train = np.array(train_df['text_features'].tolist())\n",
    "label_train = train_df['label'].values\n",
    "\n",
    "image_test = np.array(test_df.iloc[:, :-2].values.tolist())\n",
    "text_test = np.array(test_df['text_features'].tolist())\n",
    "label_test = test_df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgqXz-IwJpLN"
   },
   "source": [
    "The triplet loss function is defined as follows:\n",
    "\n",
    "$$\n",
    "L = \\max \\left( d(a, p) - d(a, n) + \\text{margin}, 0 \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( L \\) is the triplet loss value.\n",
    "- \\( d(a, p) \\) is the distance between the anchor and positive samples.\n",
    "- \\( d(a, n) \\) is the distance between the anchor and negative samples.\n",
    "- \\( \\text{margin} \\) is a margin hyperparameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KQ-SVKiJqAs"
   },
   "outputs": [],
   "source": [
    "# Define Triplet Loss\n",
    "def triplet_loss(alpha=0.4): # alpha is Margin\n",
    "    def loss(y_true, y_pred):\n",
    "        total_length = y_pred.shape[-1]\n",
    "        #three tensors: anchor, positive, and negative\n",
    "        anchor, positive, negative = y_pred[:, :total_length//3], y_pred[:, total_length//3:2*total_length//3], y_pred[:, 2*total_length//3:]\n",
    "\n",
    "        #Euclidean distances\n",
    "        pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
    "        neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
    "\n",
    "        basic_loss = pos_dist - neg_dist + alpha\n",
    "        #tf.reduce_mean() is used to aggregate the individual triplet loss\n",
    "        return tf.reduce_mean(tf.maximum(basic_loss, 0.0)) #L=max(d(a,p)−d(a,n)+margin,0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FjQr4jS5Jsz-"
   },
   "outputs": [],
   "source": [
    "# Enhanced Model Architecture\n",
    "input_dim = aligned_image_features.shape[1]\n",
    "#dimensionality of the embedding space\n",
    "#embedding_dim = 128    Test: 10, 16, 32, 64, and 128\n",
    "embedding_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QvHdbV9iJuUP"
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "anchor_input = Input(shape=(input_dim,), name=\"anchor_input\")\n",
    "positive_input = Input(shape=(input_dim,), name=\"positive_input\")\n",
    "negative_input = Input(shape=(input_dim,), name=\"negative_input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHvvnlxxJv3q"
   },
   "source": [
    "### Siamese neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RqHdIgwLJwVg"
   },
   "outputs": [],
   "source": [
    "# Shared embedding layer with BatchNormalization and Dropout\n",
    "def create_embedding_network(input):\n",
    "    x = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(input)  # Increased units\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)  # Adjusted dropout rate\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)  # Adjusted dropout rate\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PiriY5dCJzYh"
   },
   "outputs": [],
   "source": [
    "anchor_embedding = create_embedding_network(anchor_input)\n",
    "positive_embedding = create_embedding_network(positive_input)\n",
    "negative_embedding = create_embedding_network(negative_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sD3P_FWSJ08y"
   },
   "outputs": [],
   "source": [
    "# Concatenate embeddings\n",
    "#which contains representations of anchor, positive, and negative inputs stacked together in a Siamese neural network architecture.\n",
    "combined_embeddings = tf.concat([anchor_embedding, positive_embedding, negative_embedding], axis=-1)\n",
    "\n",
    "# Build the model\n",
    "model = Model(inputs=[anchor_input, positive_input, negative_input], outputs=combined_embeddings)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=triplet_loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvWLkrzIJ2qc"
   },
   "outputs": [],
   "source": [
    "# Data preparation for triplets\n",
    "def create_triplets(image_features, text_features, image_labels, num_triplets):\n",
    "    triplets = []\n",
    "    num_classes = len(np.unique(image_labels))\n",
    "    for _ in range(num_triplets):\n",
    "        anchor_idx = np.random.randint(0, len(image_labels))#randomly select an index from the range of available indices in the dataset\n",
    "        anchor_label = image_labels[anchor_idx]\n",
    "        positive_idx = np.random.choice(np.where(image_labels == anchor_label)[0])\n",
    "        negative_idx = np.random.choice(np.where(image_labels != anchor_label)[0])\n",
    "        triplets.append((image_features[anchor_idx], text_features[positive_idx], text_features[negative_idx]))\n",
    "    triplets = np.array(triplets)\n",
    "    return triplets[:, 0], triplets[:, 1], triplets[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kce-Rw1nJ4ns"
   },
   "outputs": [],
   "source": [
    "# Generate triplets for training\n",
    "triplets_train = create_triplets(image_train, text_train, label_train, num_triplets=20000) # for num_triplets try 5000 10000 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A64Vgm8HJ6jQ",
    "outputId": "42bb4005-1511-4e5b-a37e-de0f87968161"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit([triplets_train[0], triplets_train[1], triplets_train[2]], np.zeros((triplets_train[0].shape[0], 1)), epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "pi7_ynzNsSUH",
    "outputId": "35d202c3-1d2e-4ebe-9d31-ca369613e4de"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate triplets for testing\n",
    "triplets_test = create_triplets(image_test, text_test, label_test, num_triplets=5000)\n",
    "\n",
    "# Evaluate the model on the test triplets\n",
    "test_loss = model.evaluate([triplets_test[0], triplets_test[1], triplets_test[2]], np.zeros((triplets_test[0].shape[0], 1)))\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojn92xvBJ8Ry",
    "outputId": "d06e16c5-29ac-4436-8058-f19bebe7b941"
   },
   "outputs": [],
   "source": [
    "# Generate embeddings for test data\n",
    "anchor_embeddings_test = model.predict([image_test, text_test, text_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Af259FliJ93B",
    "outputId": "d2d58cf4-0844-4d0d-a4b5-ffd0ccd7c3c9"
   },
   "outputs": [],
   "source": [
    "# Define recall@k function\n",
    "def recall_at_k(embeddings, labels, k):\n",
    "    recalls = []\n",
    "    for i, anchor_embedding in enumerate(embeddings):\n",
    "        distances = np.linalg.norm(embeddings - anchor_embedding, axis=1) #Euclidean distance\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        top_k_indices = sorted_indices[1:k+1]  # Exclude the anchor itself\n",
    "        true_positives = np.sum(labels[top_k_indices] == labels[i])\n",
    "        recalls.append(true_positives / k)\n",
    "    return np.mean(recalls)\n",
    "\n",
    "# Evaluate Recall@1, Recall@5, and Recall@10 on test data\n",
    "for k in [1, 5, 10]:\n",
    "    recall_at_k_test = recall_at_k(anchor_embeddings_test, label_test, k)\n",
    "    print(\"Recall@{} on test data: {:.2f}%\".format(k, recall_at_k_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RuZpWzxJ_9x"
   },
   "source": [
    "The Euclidean distance between two points $ P = (p_1, p_2, \\ldots, p_n) $ and $ Q = (q_1, q_2, \\ldots, q_n) $ in $ n $-dimensional space is calculated using the following formula:\n",
    "\n",
    "$\\text{Euclidean distance} = \\sqrt{\\sum_{i=1}^{n} (q_i - p_i)^2}$\n",
    "\n",
    "In this formula:\n",
    "- $ n $ represents the number of dimensions (or features) in the space.\n",
    "- $ p_i $ and $ q_i $ are the $ i $th components of points $ P $ and $ Q $, respectively.\n",
    "\n",
    "This formula computes the square root of the sum of the squared differences between corresponding components of the two points. It represents the straight-line distance between the two points in the $ n $-dimensional space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4a-b2MFKAUv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "def prepare_triplet_data(image_csv, text_csv, input_dim):\n",
    "    # Load the data\n",
    "    image_df = pd.read_csv(image_csv)\n",
    "    text_df = pd.read_csv(text_csv)\n",
    "\n",
    "    # Drop any rows with NaN values (if any)\n",
    "    image_df.dropna(inplace=True)\n",
    "    text_df.dropna(inplace=True)\n",
    "\n",
    "    # Extract features and image names\n",
    "    image_feature_values = image_df.iloc[:, :-1].values\n",
    "    image_image_name_values = image_df.iloc[:, -1].values\n",
    "\n",
    "    text_feature_values = text_df.iloc[:, :-1].values\n",
    "    text_image_name_values = text_df.iloc[:, -1].values\n",
    "\n",
    "    # Create dataframes with labels as a column\n",
    "    image_df = pd.DataFrame(image_feature_values)\n",
    "    image_df['image_name'] = image_image_name_values\n",
    "\n",
    "    text_df = pd.DataFrame(text_feature_values)\n",
    "    text_df['image_name'] = text_image_name_values\n",
    "\n",
    "    # Find common image names\n",
    "    common_image_names = np.intersect1d(image_image_name_values, text_image_name_values)\n",
    "\n",
    "    # Filter dataframes to include only common image names\n",
    "    image_df = image_df[image_df['image_name'].isin(common_image_names)]\n",
    "    text_df = text_df[text_df['image_name'].isin(common_image_names)]\n",
    "\n",
    "    # Ensure the dataframes are sorted by image names\n",
    "    image_df = image_df.sort_values(by='image_name')\n",
    "    text_df = text_df.sort_values(by='image_name')\n",
    "\n",
    "    # Extract aligned features and labels\n",
    "    aligned_image_features = image_df.iloc[:, :-1].values\n",
    "    aligned_text_features = text_df.iloc[:, :-1].values\n",
    "    aligned_image_names = image_df['image_name'].values\n",
    "\n",
    "    # Initialize and fit the label encoder\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(aligned_image_names)\n",
    "\n",
    "    # Transform the image names to encoded labels\n",
    "    labels_encoded = encoder.transform(aligned_image_names)\n",
    "\n",
    "    # Define anchor, positive, and negative inputs\n",
    "    anchor_input = Input(shape=(input_dim,), name=\"anchor_input\")\n",
    "    positive_input = Input(shape=(input_dim,), name=\"positive_input\")\n",
    "    negative_input = Input(shape=(input_dim,), name=\"negative_input\")\n",
    "\n",
    "    return anchor_input, positive_input, negative_input, aligned_image_features, aligned_text_features, labels_encoded\n",
    "\n",
    "def recall_at_k(embeddings, labels, k):\n",
    "    recalls = []\n",
    "    for i, anchor_embedding in enumerate(embeddings):\n",
    "        distances = np.linalg.norm(embeddings - anchor_embedding, axis=1) # Euclidean distance\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        top_k_indices = sorted_indices[1:k+1]  # Exclude the anchor itself\n",
    "        true_positives = np.sum(labels[top_k_indices] == labels[i])\n",
    "        recalls.append(true_positives / k)\n",
    "    return np.mean(recalls)\n",
    "\n",
    "# Example usage\n",
    "image_csv_path = '/content/Text_Rasti.csv'\n",
    "text_csv_path = '/content/Image_Rasti_test.csv'\n",
    "input_dim = 16  # Example input dimension\n",
    "\n",
    "anchor_input, positive_input, negative_input, aligned_image_features, aligned_text_features, labels_encoded = prepare_triplet_data(image_csv_path, text_csv_path, input_dim)\n",
    "\n",
    "# Evaluate Recall@1, Recall@5, and Recall@10 on test data\n",
    "for k in [1, 5, 10]:\n",
    "    recall_at_k_test = recall_at_k(aligned_image_features, labels_encoded, k)\n",
    "    print(\"Recall@{} on test data: {:.2f}%\".format(k, recall_at_k_test * 100))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
